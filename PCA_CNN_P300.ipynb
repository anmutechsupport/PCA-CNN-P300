{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA-CNN P300",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmutechsupport/PCA-CNN-P300/blob/main/PCA_CNN_P300.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnxigHwOJV3G"
      },
      "source": [
        "pip install tensorflow_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iebh74wcPHx1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, concatenate, Conv3D\n",
        "from pprint import pprint\n",
        "# import tensorflow_transform as tft\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import seaborn as sns\n",
        "\n",
        "# import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xnQWfkpUyO-"
      },
      "source": [
        "# K.set_image_data_format('channels_last') #does not work\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTPEWYWVvJyF",
        "outputId": "a3f129f7-be96-4021-835f-07d811b8579f"
      },
      "source": [
        "def minibatch(data, batch_size):\n",
        "    start = 0\n",
        "    while True:\n",
        "\n",
        "        end = start + batch_size\n",
        "        yield data[start:end]\n",
        "\n",
        "        start = end\n",
        "        if start >= len(data):\n",
        "            break\n",
        "\n",
        "# function to collect matching files and dirs\n",
        "def collect_files(root, res, pattern=\"\", collect_dirs=True, min_depth=None, max_depth=None):\n",
        "    \n",
        "    # check max depth\n",
        "    if not max_depth is None and max_depth == 0:\n",
        "        return\n",
        "    \n",
        "    # go through all item in the dir\n",
        "    for item in os.listdir(root):\n",
        "        \n",
        "        # process item\n",
        "        item_path = os.path.join(root, item)\n",
        "        item_is_dir = os.path.isdir(item_path)\n",
        "        \n",
        "        # pull valid file in res if min depth has reached\n",
        "        if min_depth is None or min_depth - 1 <= 0:\n",
        "            if re.match(pattern, item_path):\n",
        "                if not item_is_dir or collect_dirs:\n",
        "                    res.append(item_path)\n",
        "        \n",
        "        # recursively collect all files\n",
        "        if item_is_dir:\n",
        "            next_min_depth = None if min_depth is None else min_depth - 1\n",
        "            next_max_depth = None if max_depth is None else max_depth - 1\n",
        "            collect_files(item_path, res, pattern, collect_dirs, next_min_depth, next_max_depth)\n",
        "\n",
        "# collect the mat files\n",
        "mat_files = []\n",
        "collect_files(\"./\", mat_files, pattern=\".*\\.mat$\", collect_dirs=False)\n",
        "mat_files.sort()\n",
        "print(mat_files)\n",
        "\n",
        "# load all data into memory\n",
        "# all_data[i] means data for ith subject\n",
        "all_data = []\n",
        "for i, mat_file in enumerate(mat_files):\n",
        "    \n",
        "    # re-index tmp into a dictionary\n",
        "    tmp = loadmat(mat_file)[\"data\"][0][0]\n",
        "    tmp = {name: data for name, data in zip(tmp.dtype.names, tmp)}\n",
        "    \n",
        "    # rename column\n",
        "    tmp[\"x\"] = tmp[\"X\"]\n",
        "    del tmp[\"X\"]\n",
        "    \n",
        "    # reshape columns\n",
        "    tmp[\"y\"] = tmp[\"y\"].reshape(-1)\n",
        "    tmp[\"y_stim\"] = tmp[\"y_stim\"].reshape(-1)\n",
        "    tmp[\"trial\"] = tmp[\"trial\"].reshape(-1)\n",
        "    \n",
        "    # add subject info\n",
        "    tmp[\"subject\"] = i + 1\n",
        "    \n",
        "    all_data.append(tmp)\n",
        "\n",
        "pprint(all_data[0])\n",
        "\n",
        "# constants for data_extraction\n",
        "sample_rate = 250 #hz\n",
        "tick_len = 1000 // sample_rate # ms -> 4\n",
        "pre_epoch = 0 #ms\n",
        "post_epoch = 700 #ms\n",
        "\n",
        "raw = all_data[0]['x']\n",
        "print(np.array(raw.shape))\n",
        "\n",
        "# give raw eeg data and tick times, return 2d signals\n",
        "def extract_epochs(raw, ticks):\n",
        "    pre_tick = int(pre_epoch // tick_len) # 0\n",
        "    post_tick = int(post_epoch // tick_len) #175\n",
        "    raw_len = len(raw) #350k+ datapoints -> each experiment is 1400s long -> sampling at 250hz \n",
        "    signals = [] \n",
        "    for t in ticks:\n",
        "        if t + post_tick <= raw_len: \n",
        "            signal = raw[t-pre_tick:t+post_tick, :] #takes slice of data points, takes all electrodes\n",
        "            signals.append(signal)\n",
        "    return np.array(signals) #1st dim == # of sample point ids\n",
        "\n",
        "# extract epochs for every subject\n",
        "for i, data in enumerate(all_data):\n",
        "    \n",
        "    # extract from raw\n",
        "    ticks, y_stim, y = data[\"flash\"][:, [0, 2, 3]].T #extracts sample point id, stimulation(0-12), hit/nohits(1/2)\n",
        "    raw = data[\"x\"]\n",
        "    \n",
        "    # get the epochs\n",
        "    epochs = extract_epochs(raw, ticks) #returning signals -> we only slice from sample point ids, why?\n",
        "    \n",
        "    # label the epochs\n",
        "    for j, x in enumerate(y):\n",
        "        assert x == 1 or x == 2\n",
        "        y[j] = 1 if x == 2 else 0 #switching labels from 1/2 to 0/1\n",
        "    \n",
        "    # trim extra y and y_stim\n",
        "    y = y[:len(epochs)] #takes all the labels until # of sample point ids\n",
        "    y_stim = y_stim[:len(epochs)] #takes all the stim until # of sample point ids\n",
        "    \n",
        "    assert len(epochs) == len(y) and len(y) == len(y_stim) # validating stuff that we did in the 2 lines above \n",
        "    \n",
        "    samples = np.array(list(zip(epochs, y, y_stim)), dtype=object) # concatenates everything into an np array\n",
        "    \n",
        "    # save the data\n",
        "    with open(f\"s{i+1}.pkl\", \"wb\") as outfile:\n",
        "        pickle.dump(samples, outfile) #saves sample np array into pkl\n",
        "\n",
        "print(samples.shape)\n",
        "\n",
        "with open(\"s7.pkl\", \"rb\") as infile:\n",
        "    data = pickle.load(infile)\n",
        "\n",
        "a = []\n",
        "for i in data[:, 0]: #appending data batches into 'a'\n",
        "    a.append(i)\n",
        "\n",
        "# print('a', np.array(a).shape)\n",
        "# a = np.array(a).reshape(4200, 8, 175)\n",
        "\n",
        "# for i in range(1, 9):\n",
        "#     with open(f\"s{i}.pkl\", \"rb\") as infile:\n",
        "#         data = pickle.load(infile)\n",
        "#         target = np.sum(data[:, 1]) #Adds all the labels together\n",
        "#         print(target, len(data) - target) #hits:nohits\n",
        "\n",
        "data_size = len(data)\n",
        "print([i for i in data[:, 1]]) #use these to decode with a simple if loop ->  not super sure if each stim represents one flash\n",
        "\n",
        "# shuffle data\n",
        "shuffle_idx = np.random.permutation(data_size)\n",
        "data = data[shuffle_idx]\n",
        "\n",
        "# 80-20 split train/test\n",
        "cutoff = int(data_size * 80 // 100)\n",
        "train_data = data[:cutoff]\n",
        "val_data = data[cutoff:]\n",
        "\n",
        "# balance label in the train_data\n",
        "train_data_size = len(train_data)\n",
        "train_data_true_count = np.sum([x[1] for x in train_data]) #taking sum of hit labels\n",
        "train_data_false_count = train_data_size - train_data_true_count #finding # of nohit labels\n",
        "\n",
        "assert train_data_false_count >= train_data_true_count \n",
        "\n",
        "train_data_dup_count = train_data_false_count - train_data_true_count \n",
        "train_data_true_idx = np.array([i for i, x in enumerate(train_data) if x[1] == 1])#index array of train data hit labels\n",
        "train_data_true_sample_idx = np.random.choice(train_data_true_idx, train_data_dup_count, replace=True) #creates random sample indices with and size of dup_count\n",
        "train_data_addon = train_data[train_data_true_sample_idx] #creates array using indices above\n",
        "\n",
        "# make sure that all the addon have true labels\n",
        "assert all([x[1] == 1 for x in train_data_addon])\n",
        "\n",
        "# stack the addon to the original trainning data and shuffle again\n",
        "train_data = np.concatenate((train_data, train_data_addon), axis=0)\n",
        "train_data_size = len(train_data)\n",
        "shuffle_idx = np.random.permutation(train_data_size)\n",
        "train_data = train_data[shuffle_idx] #final dataset\n",
        "\n",
        "'''\n",
        "'''\n",
        "\n",
        "# train_data = train_data[:(len(train_data)*10//100)]\n",
        "\n",
        "# data = np.array([i for i in data[:, 0]])\n",
        "# labels = np.array(data[:, 1])\n",
        "# stim = np.array(data[:, 2])\n",
        " \n",
        "T_data = np.array([i for i in train_data[:, 0]])\n",
        "T_labels = np.array([i for i in train_data[:, 1]])\n",
        "T_stim = np.array([i for i in train_data[:, 2]])\n",
        "\n",
        "V_data = np.array([i for i in val_data[:, 0]])\n",
        "V_labels = np.array([i for i in val_data[:, 1]])\n",
        "V_stim = np.array([i for i in val_data[:, 2]])\n",
        "\n",
        "print(len(data))\n",
        "print(V_labels.shape, T_data.shape)\n",
        "\n",
        "with open(f\"labels.pkl\", \"wb\") as outfile:\n",
        "  pickle.dump([T_labels, V_labels], outfile)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./P300S01.mat', './P300S02.mat', './P300S03.mat', './P300S04.mat', './P300S05.mat', './P300S06.mat', './P300S07.mat', './P300S08.mat']\n",
            "{'flash': array([[  7486,     31,     11,      1],\n",
            "       [  7548,     31,      5,      1],\n",
            "       [  7610,     30,      7,      1],\n",
            "       ...,\n",
            "       [355688,     32,      3,      2],\n",
            "       [355750,     32,      7,      1],\n",
            "       [355813,     32,      4,      1]], dtype=int32),\n",
            " 'subject': 1,\n",
            " 'trial': array([  7487,  17511,  27536,  37564,  47590,  57620,  67641,  77667,\n",
            "        87690,  97715, 107740, 117764, 127790, 137813, 147840, 157867,\n",
            "       167893, 177915, 187942, 197967, 207995, 218018, 228044, 238068,\n",
            "       248095, 258119, 268146, 278171, 288194, 298220, 308246, 318273,\n",
            "       328297, 338325, 348349], dtype=int32),\n",
            " 'x': array([[26.95640373, 11.73869324,  6.98503304, ...,  2.66381407,\n",
            "        -3.04957318, -2.63618731],\n",
            "       [29.94702721, 14.98267174, 10.02626705, ...,  5.16736984,\n",
            "         1.30663943,  2.16391516],\n",
            "       [33.09702683, 19.32771683, 13.60309792, ...,  8.05283546,\n",
            "         8.53473663,  7.90571976],\n",
            "       ...,\n",
            "       [ 5.6236558 ,  0.53022534,  1.55959177, ..., -4.96036482,\n",
            "         2.35364461, -8.1143961 ],\n",
            "       [ 4.38928461,  1.46526659,  1.96254373, ..., -4.6057415 ,\n",
            "         1.29674733, -7.18669939],\n",
            "       [ 2.58838463,  0.79275906,  0.29564747, ..., -4.98137999,\n",
            "        -4.04607677, -7.54975986]]),\n",
            " 'y': array([0, 0, 0, ..., 0, 0, 0], dtype=uint8),\n",
            " 'y_stim': array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)}\n",
            "[358372      8]\n",
            "(4198, 3)\n",
            "[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "hello (3358, 3)\n",
            "hello (5610, 3)\n",
            "4198\n",
            "(840,) (5610, 175, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbaJ50AMupCL"
      },
      "source": [
        "def standardize_data(arr):\n",
        "         \n",
        "    '''\n",
        "    This function standardize an array, its substracts mean value, \n",
        "    and then divide the standard deviation.\n",
        "    \n",
        "    param 1: array \n",
        "    return: standardized array\n",
        "    '''    \n",
        "    rows, columns = arr.shape\n",
        "    \n",
        "    standardizedArray = np.zeros(shape=(rows, columns)) \n",
        "    tempArray = np.zeros(rows)  \n",
        "    \n",
        "    for column in tqdm(range(columns)):\n",
        "        \n",
        "        # print(column)\n",
        "        mean = np.mean(X[:,column]) #mean of channel\n",
        "        std = np.std(X[:,column]) #std of channel\n",
        "        tempArray = np.empty(0)\n",
        "        \n",
        "        for element in X[:,column]: \n",
        "            \n",
        "            tempArray = np.append(tempArray, ((element - mean) / std)) #row val - mean/std = mean of 0, STD of 1\n",
        " \n",
        "        standardizedArray[:,column] = tempArray\n",
        "    \n",
        "    return standardizedArray\n",
        "\n",
        "ink = np.random.randn(50,64,240) #numpy\n",
        "\n",
        "PCA_array = [[], []]\n",
        "datax = [T_data, V_data]\n",
        "\n",
        "for data in tqdm(datax):\n",
        "# Standardizing data\n",
        "  X = data.reshape(len(data)*8, 175) #flatten axis for standardizing\n",
        "  X = standardize_data(X).reshape(-1, 8, 175)\n",
        "  # print(X.shape)\n",
        "\n",
        "  for batch in X:\n",
        "    # Calculating the covariance matrix\n",
        "    covariance_matrix = np.cov(batch.T)\n",
        "    # print(covariance_matrix)\n",
        "\n",
        "    # Using np.linalg.eig function\n",
        "    eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
        "    # print(\"Eigenvector: \\n\",eigen_vectors,\"\\n\")\n",
        "    # print(\"Eigenvalues: \\n\", eigen_values, \"\\n\")\n",
        "\n",
        "  # Calculating the explained variance on each of components\n",
        "    variance_explained = []\n",
        "    for i in eigen_values:\n",
        "        variance_explained.append((i/sum(eigen_values))*100)\n",
        "          \n",
        "    # print(variance_explained)\n",
        "\n",
        "  # Identifying components that explain at least 95%\n",
        "\n",
        "    cumulative_variance_explained = np.cumsum(variance_explained)\n",
        "    # print(cumulative_variance_explained)\n",
        "\n",
        "  # Using two first components (because those explain more than 95%)\n",
        "    projection_matrix = (eigen_vectors.T[:][:60]).T\n",
        "    # print(projection_matrix)\n",
        "\n",
        "  # Getting the product of original standardized X and the eigenvectors \n",
        "    batch_pca = batch.dot(projection_matrix)\n",
        "    PCA_array[datax.index(data)].append(batch_pca)\n",
        "\n",
        "# print(PCA_array)\n",
        "PCA_array = np.array([np.array(x) for x in PCA_array], dtype=object)\n",
        "print(PCA_array.shape)\n",
        "with open(f\"PCA1.pkl\", \"wb\") as outfile:\n",
        "  pickle.dump(PCA_array, outfile)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJa3YkCyEc9W",
        "outputId": "4e3ad7ac-c2db-4506-dce3-1c430f4b13bc"
      },
      "source": [
        "with open(\"PCA1.pkl\", \"rb\") as infile:\n",
        "    pca = pickle.load(infile)\n",
        "\n",
        "print(pca[1].shape)\n",
        "\n",
        "#hold out split\n",
        "PCA_val, PCA_train = pca[1].reshape(-1, 8, 60, 1),  pca[0].reshape(-1, 8, 60, 1)\n",
        "\n",
        "PCA_train.shape\n",
        "\n",
        "\n",
        "# print(PCA_val.shape, PCA_train.shape, labels_val.shape, labels_train.shape, labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(840, 8, 60)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5610, 8, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiwW-p2w6kqF",
        "outputId": "6cf071f3-1ac0-4cb0-988b-e20a73797792"
      },
      "source": [
        "with open(\"labels.pkl\", \"rb\") as infile:\n",
        "    T_labels, V_labels = pickle.load(infile)\n",
        "\n",
        "print(T_labels.shape)\n",
        "print(V_labels.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5610,)\n",
            "(840,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGWQ29k_Q1w4"
      },
      "source": [
        "120 dim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_E92qlePUkp",
        "outputId": "46699515-a617-454d-8b3d-b751254a6220"
      },
      "source": [
        "model = models.Sequential()\n",
        "inp_conc1 = Input(shape=(1, 120, 20))\n",
        "inp_conc2 = Input(shape=(1, 44, 16))\n",
        "\n",
        "#l2\n",
        "model.add(Conv2D(20, (8, 1), activation=\"relu\", strides=(8, 1), padding='same', input_shape=(8, 120, 1))) #just change kernel size here and you should be good to go with any array\n",
        "# print(L2.shape) #0th index: # of batches, 1st index: height of output, 2nd index: width of output, 3rd index: depth -> # of filters\n",
        "#l3\n",
        "L3_1 = Conv2D(filters=16, kernel_size=(1, 5), strides=(1, 5), padding=\"same\", activation=\"relu\", input_shape=(1, 120, 20))(inp_conc1)\n",
        "# print(L3_1.shape)\n",
        "\n",
        "L3_2 = Conv2D(filters=16, kernel_size=(1, 10), strides=(1, 10), padding=\"same\", activation=\"relu\", input_shape=(1, 120, 20))(inp_conc1)\n",
        "# # print(L3_2.shape)\n",
        "\n",
        "L3_3 = Conv2D(filters=16, kernel_size=(1, 15), strides=(1, 15), padding=\"same\", activation=\"relu\", input_shape=(1, 120, 20))(inp_conc1)\n",
        "# print(L3_3.shape)\n",
        "\n",
        "#L4\n",
        "L3_concat = models.Model(inputs=inp_conc1, outputs=concatenate([L3_1, L3_2, L3_3], axis=2))\n",
        "model.add(L3_concat)\n",
        "model.add(tf.keras.layers.Dropout(.5))\n",
        "# print(dp.shape)\n",
        "\n",
        "#L5\n",
        "L5_1 = Conv2D(filters=16, kernel_size=(1, 2), strides=(1, 2), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(inp_conc2)\n",
        "# print(L5_1.shape)\n",
        "\n",
        "L5_2 = Conv2D(filters=16, kernel_size=(1, 4), strides=(1, 4), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(inp_conc2)\n",
        "# print(L5_2.shape)\n",
        "\n",
        "L5_3 = Conv2D(filters=16, kernel_size=(1, 11), strides=(1, 11), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(inp_conc2)\n",
        "# print(L5_3.shape)\n",
        "\n",
        "#L6\n",
        "L5_concat = models.Model(inputs=inp_conc2, outputs=concatenate([L5_1, L5_2, L5_3], axis=2))\n",
        "model.add(L5_concat)\n",
        "model.add(tf.keras.layers.Dropout(.5))\n",
        "# print(dp2.shape)\n",
        "\n",
        "#L7\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=2, padding='same'))\n",
        "# print(mxpool.shape)\n",
        "\n",
        "#L8 \n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(2, activation='relu'))\n",
        "# print(dense.shape)\n",
        "# print(dense2.shape)\n",
        "\n",
        "#L9\n",
        "model.add(layers.Softmax(axis=1))\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_86 (Conv2D)           (None, 1, 120, 20)        180       \n",
            "_________________________________________________________________\n",
            "model_24 (Functional)        (None, 1, 44, 16)         9648      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 1, 44, 16)         0         \n",
            "_________________________________________________________________\n",
            "model_25 (Functional)        (None, 1, 37, 16)         4400      \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 1, 37, 16)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 1, 19, 16)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 304)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 100)               30500     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "softmax_12 (Softmax)         (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 44,930\n",
            "Trainable params: 44,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyeaU6p3O-wb"
      },
      "source": [
        "60 dim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO-n4x0ORca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fab5c54-bfc6-4b1a-bb07-dfc71f08e9f0"
      },
      "source": [
        "model = models.Sequential()\n",
        "inp_conc1 = Input(shape=(1, 60, 20))\n",
        "inp_conc2 = Input(shape=(1, 22, 16))\n",
        "\n",
        "#l2\n",
        "model.add(Conv2D(20, (8, 1), activation=\"relu\", strides=(8, 1), padding='same', input_shape=(8, 60, 1))) #just change kernel size here and you should be good to go with any array\n",
        "# print(L2.shape) #0th index: # of batches, 1st index: height of output, 2nd index: width of output, 3rd index: depth -> # of filters\n",
        "#l3\n",
        "L3_1 = Conv2D(filters=16, kernel_size=(1, 5), strides=(1, 5), padding=\"same\", activation=\"relu\", input_shape=(1, 60, 20))(inp_conc1)\n",
        "# print(L3_1.shape)\n",
        "\n",
        "L3_2 = Conv2D(filters=16, kernel_size=(1, 10), strides=(1, 10), padding=\"same\", activation=\"relu\", input_shape=(1, 60, 20))(inp_conc1)\n",
        "# # print(L3_2.shape)\n",
        "\n",
        "L3_3 = Conv2D(filters=16, kernel_size=(1, 15), strides=(1, 15), padding=\"same\", activation=\"relu\", input_shape=(1, 60, 20))(inp_conc1)\n",
        "# print(L3_3.shape)\n",
        "\n",
        "#L4\n",
        "L3_concat = models.Model(inputs=inp_conc1, outputs=concatenate([L3_1, L3_2, L3_3], axis=2))\n",
        "model.add(L3_concat)\n",
        "model.add(tf.keras.layers.Dropout(.5))\n",
        "# print(dp.shape)\n",
        "\n",
        "#L5\n",
        "L5_1 = Conv2D(filters=16, kernel_size=(1, 2), strides=(1, 2), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(inp_conc2)\n",
        "# print(L5_1.shape)\n",
        "\n",
        "L5_2 = Conv2D(filters=16, kernel_size=(1, 4), strides=(1, 4), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(inp_conc2)\n",
        "# print(L5_2.shape)\n",
        "\n",
        "L5_3 = Conv2D(filters=16, kernel_size=(1, 11), strides=(1, 11), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(inp_conc2)\n",
        "# print(L5_3.shape)\n",
        "\n",
        "#L6\n",
        "L5_concat = models.Model(inputs=inp_conc2, outputs=concatenate([L5_1, L5_2, L5_3], axis=2))\n",
        "model.add(L5_concat)\n",
        "model.add(tf.keras.layers.Dropout(.5))\n",
        "# print(dp2.shape)\n",
        "\n",
        "#L7\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=2, padding='same'))\n",
        "# print(mxpool.shape)\n",
        "\n",
        "#L8 \n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(2, activation='relu'))\n",
        "# print(dense.shape)\n",
        "# print(dense2.shape)\n",
        "\n",
        "#L9\n",
        "model.add(layers.Softmax(axis=1))\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_42 (Conv2D)           (None, 1, 60, 20)         180       \n",
            "_________________________________________________________________\n",
            "model_12 (Functional)        (None, 1, 22, 16)         9648      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1, 22, 16)         0         \n",
            "_________________________________________________________________\n",
            "model_13 (Functional)        (None, 1, 19, 16)         4400      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1, 19, 16)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 10, 16)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               16100     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 30,530\n",
            "Trainable params: 30,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHUyRZWmRhto"
      },
      "source": [
        "Dynamic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK4tWVTPN4kE",
        "outputId": "7388175b-2158-43f4-d899-e1525042d2bb"
      },
      "source": [
        "model = models.Sequential()\n",
        "dim = PCA_val.shape[2]  \n",
        "inp_conc1 = Input(shape=(1, dim, 20))\n",
        "inp_conc2 = Input(shape=(1, int(dim/5+dim/10+dim/15), 16))\n",
        "\n",
        "#l2\n",
        "model.add(Conv2D(20, (8, 1), activation=\"relu\", strides=(8, 1), padding='same', input_shape=(8, 60, 1))) #just change kernel size here and you should be good to go with any array\n",
        "# print(L2.shape) #0th index: # of batches, 1st index: height of output, 2nd index: width of output, 3rd index: depth -> # of filters\n",
        "#l3\n",
        "L3_1 = Conv2D(filters=16, kernel_size=(1, 5), strides=(1, 5), padding=\"same\", activation=\"relu\")(inp_conc1)\n",
        "# print(L3_1.shape)\n",
        "\n",
        "L3_2 = Conv2D(filters=16, kernel_size=(1, 10), strides=(1, 10), padding=\"same\", activation=\"relu\")(inp_conc1)\n",
        "# # print(L3_2.shape)\n",
        "\n",
        "L3_3 = Conv2D(filters=16, kernel_size=(1, 15), strides=(1, 15), padding=\"same\", activation=\"relu\")(inp_conc1)\n",
        "# print(L3_3.shape)\n",
        "\n",
        "#L4\n",
        "L3_concat = models.Model(inputs=inp_conc1, outputs=concatenate([L3_1, L3_2, L3_3], axis=2))\n",
        "model.add(L3_concat)\n",
        "model.add(tf.keras.layers.Dropout(.5))\n",
        "# print(dp.shape)\n",
        "\n",
        "#L5\n",
        "L5_1 = Conv2D(filters=16, kernel_size=(1, 2), strides=(1, 2), padding=\"same\", activation=\"relu\")(inp_conc2)\n",
        "# print(L5_1.shape)\n",
        "\n",
        "L5_2 = Conv2D(filters=16, kernel_size=(1, 4), strides=(1, 4), padding=\"same\", activation=\"relu\")(inp_conc2)\n",
        "# print(L5_2.shape)\n",
        "\n",
        "L5_3 = Conv2D(filters=16, kernel_size=(1, 11), strides=(1, 11), padding=\"same\", activation=\"relu\")(inp_conc2)\n",
        "# print(L5_3.shape)\n",
        "\n",
        "#L6\n",
        "L5_concat = models.Model(inputs=inp_conc2, outputs=concatenate([L5_1, L5_2, L5_3], axis=2))\n",
        "model.add(L5_concat)\n",
        "model.add(tf.keras.layers.Dropout(.5))\n",
        "# print(dp2.shape)\n",
        "\n",
        "#L7\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=2, padding='same'))\n",
        "# print(mxpool.shape)\n",
        "\n",
        "#L8 \n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(2, activation=tf.keras.activations.softmax)) #fix this, figure out softmax dense layer\n",
        "# print(dense.shape)\n",
        "# print(dense2.shape)\n",
        "\n",
        "# #L9\n",
        "# model.add(layers.Softmax(axis=1))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 1, 60, 20)         180       \n",
            "_________________________________________________________________\n",
            "model (Functional)           (None, 1, 22, 16)         9648      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 22, 16)         0         \n",
            "_________________________________________________________________\n",
            "model_1 (Functional)         (None, 1, 19, 16)         4400      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 19, 16)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 10, 16)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               16100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 30,530\n",
            "Trainable params: 30,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb-A3jje0tOy"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayKcgeXO0siD",
        "outputId": "850e7b03-f51c-41df-aa89-137664155a26"
      },
      "source": [
        "history = model.fit(PCA_train, T_labels, epochs=30, \n",
        "                    validation_data=(PCA_val, V_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.7065 - accuracy: 0.5143 - val_loss: 0.6586 - val_accuracy: 0.7429\n",
            "Epoch 2/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.6850 - accuracy: 0.5504 - val_loss: 0.6306 - val_accuracy: 0.7726\n",
            "Epoch 3/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.6704 - accuracy: 0.5818 - val_loss: 0.6671 - val_accuracy: 0.5702\n",
            "Epoch 4/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.6410 - accuracy: 0.6200 - val_loss: 0.6277 - val_accuracy: 0.6667\n",
            "Epoch 5/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.6127 - accuracy: 0.6563 - val_loss: 0.6004 - val_accuracy: 0.6964\n",
            "Epoch 6/30\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.5841 - accuracy: 0.6868 - val_loss: 0.5940 - val_accuracy: 0.7036\n",
            "Epoch 7/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.5535 - accuracy: 0.7071 - val_loss: 0.6512 - val_accuracy: 0.5988\n",
            "Epoch 8/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7328 - val_loss: 0.5937 - val_accuracy: 0.7000\n",
            "Epoch 9/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4943 - accuracy: 0.7488 - val_loss: 0.6786 - val_accuracy: 0.6298\n",
            "Epoch 10/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4659 - accuracy: 0.7640 - val_loss: 0.6404 - val_accuracy: 0.7000\n",
            "Epoch 11/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4477 - accuracy: 0.7856 - val_loss: 0.6487 - val_accuracy: 0.6845\n",
            "Epoch 12/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8034 - val_loss: 0.7003 - val_accuracy: 0.7155\n",
            "Epoch 13/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4068 - accuracy: 0.8059 - val_loss: 0.7290 - val_accuracy: 0.6560\n",
            "Epoch 14/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3969 - accuracy: 0.8118 - val_loss: 0.7339 - val_accuracy: 0.6893\n",
            "Epoch 15/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3892 - accuracy: 0.8178 - val_loss: 0.7480 - val_accuracy: 0.6940\n",
            "Epoch 16/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3752 - accuracy: 0.8234 - val_loss: 0.7930 - val_accuracy: 0.7286\n",
            "Epoch 17/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3555 - accuracy: 0.8353 - val_loss: 0.8255 - val_accuracy: 0.6881\n",
            "Epoch 18/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3450 - accuracy: 0.8349 - val_loss: 0.8255 - val_accuracy: 0.6929\n",
            "Epoch 19/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3357 - accuracy: 0.8444 - val_loss: 0.8497 - val_accuracy: 0.6893\n",
            "Epoch 20/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3401 - accuracy: 0.8383 - val_loss: 0.8601 - val_accuracy: 0.6988\n",
            "Epoch 21/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3296 - accuracy: 0.8419 - val_loss: 0.8681 - val_accuracy: 0.6762\n",
            "Epoch 22/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3162 - accuracy: 0.8483 - val_loss: 0.9598 - val_accuracy: 0.7083\n",
            "Epoch 23/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3158 - accuracy: 0.8496 - val_loss: 0.9080 - val_accuracy: 0.6833\n",
            "Epoch 24/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3144 - accuracy: 0.8563 - val_loss: 0.9648 - val_accuracy: 0.7024\n",
            "Epoch 25/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3025 - accuracy: 0.8524 - val_loss: 0.9643 - val_accuracy: 0.7119\n",
            "Epoch 26/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2935 - accuracy: 0.8684 - val_loss: 0.9695 - val_accuracy: 0.6964\n",
            "Epoch 27/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2909 - accuracy: 0.8658 - val_loss: 0.9602 - val_accuracy: 0.6869\n",
            "Epoch 28/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2756 - accuracy: 0.8718 - val_loss: 1.0091 - val_accuracy: 0.7238\n",
            "Epoch 29/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2873 - accuracy: 0.8663 - val_loss: 0.9726 - val_accuracy: 0.7107\n",
            "Epoch 30/30\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2795 - accuracy: 0.8717 - val_loss: 1.1027 - val_accuracy: 0.7143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "E7hPM0Qs8bTn",
        "outputId": "2485e618-bc7f-41b3-8c9a-b61c46e54beb"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(PCA_val,  V_labels, verbose=2)\n",
        "y_pred = np.argmax(model.predict(PCA_val), axis=-1)\n",
        "print(y_pred.shape) #TRY ARGMAX\n",
        "\n",
        "# plt.plot(y_pred[:, 0], label='accuracy')\n",
        "# plt.plot(y_pred[:, 1], label = 'val_accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Pred')\n",
        "# plt.ylim([0, 1])\n",
        "# plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27/27 - 0s - loss: 1.1027 - accuracy: 0.7143\n",
            "(840,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGmX3JPzhoM0",
        "outputId": "c9620e20-32fe-412b-d5e6-bfa161937f30"
      },
      "source": [
        "#test data\n",
        "\n",
        "with open(\"s4.pkl\", \"rb\") as infile:\n",
        "    big_data = pickle.load(infile)\n",
        "\n",
        "print([i for i in big_data[:, 1]]) #use these to decode with a simple if loop ->  not super sure if each stim represents one flash\n",
        "\n",
        "'''\n",
        "'''\n",
        "\n",
        "# train_data = train_data[:(len(train_data)*10//100)]\n",
        "\n",
        "test_data = np.array([i for i in big_data[:, 0]])\n",
        "test_labels = np.array([i for i in big_data[:, 1]])\n",
        "test_stim = np.array([i for i in big_data[:, 2]])\n",
        "\n",
        "# with open(f\"labels.pkl\", \"wb\") as outfile:\n",
        "#   pickle.dump([T_labels, V_labels], outfile)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqbKwICO5_au",
        "outputId": "e244bd74-6fe4-4f33-8fea-9569cc719552"
      },
      "source": [
        "def standardize_data(arr):\n",
        "         \n",
        "    '''\n",
        "    This function standardize an array, its substracts mean value, \n",
        "    and then divide the standard deviation.\n",
        "    \n",
        "    param 1: array \n",
        "    return: standardized array\n",
        "    '''    \n",
        "    rows, columns = arr.shape\n",
        "    \n",
        "    standardizedArray = np.zeros(shape=(rows, columns)) \n",
        "    tempArray = np.zeros(rows)  \n",
        "    \n",
        "    for column in tqdm(range(columns)):\n",
        "        \n",
        "        # print(column)\n",
        "        mean = np.mean(X[:,column]) #mean of channel\n",
        "        std = np.std(X[:,column]) #std of channel\n",
        "        tempArray = np.empty(0)\n",
        "        \n",
        "        for element in X[:,column]: \n",
        "            \n",
        "            tempArray = np.append(tempArray, ((element - mean) / std)) #row val - mean/std = mean of 0, STD of 1\n",
        " \n",
        "        standardizedArray[:,column] = tempArray\n",
        "    \n",
        "    return standardizedArray\n",
        "\n",
        "PCA_test = []\n",
        "\n",
        "# Standardizing data\n",
        "X = test_data.reshape(len(test_data)*8, 175) #flatten axis for standardizing\n",
        "X = standardize_data(X).reshape(-1, 8, 175)\n",
        "# print(X.shape)\n",
        "\n",
        "for batch in tqdm(X):\n",
        "  # Calculating the covariance matrix\n",
        "  covariance_matrix = np.cov(batch.T)\n",
        "  # print(covariance_matrix)\n",
        "\n",
        "  # Using np.linalg.eig function\n",
        "  eigen_values, eigen_vectors = np.linalg.eig(covariance_matrix)\n",
        "  # print(\"Eigenvector: \\n\",eigen_vectors,\"\\n\")\n",
        "  # print(\"Eigenvalues: \\n\", eigen_values, \"\\n\")\n",
        "\n",
        "# Calculating the explained variance on each of components\n",
        "  variance_explained = []\n",
        "  for i in eigen_values:\n",
        "      variance_explained.append((i/sum(eigen_values))*100)\n",
        "        \n",
        "  # print(variance_explained)\n",
        "\n",
        "# Identifying components that explain at least 95%\n",
        "\n",
        "  cumulative_variance_explained = np.cumsum(variance_explained)\n",
        "  # print(cumulative_variance_explained)\n",
        "\n",
        "# Using two first components (because those explain more than 95%)\n",
        "  projection_matrix = (eigen_vectors.T[:][:60]).T\n",
        "  # print(projection_matrix)\n",
        "\n",
        "# Getting the product of original standardized X and the eigenvectors \n",
        "  batch_pca = batch.dot(projection_matrix)\n",
        "  PCA_test.append(batch_pca)\n",
        "\n",
        "# print(PCA_array)\n",
        "PCA_test = np.array(PCA_test).real\n",
        "print(PCA_test.shape)\n",
        "with open(f\"PCA_test.pkl\", \"wb\") as outfile:\n",
        "  pickle.dump(PCA_test, outfile)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 175/175 [01:09<00:00,  2.51it/s]\n",
            "100%|| 4198/4198 [03:55<00:00, 17.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(4198, 8, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejx4etKk-cMw",
        "outputId": "ca10c0d8-424a-4724-ac39-f0d3a5f44186"
      },
      "source": [
        "with open(\"PCA_test.pkl\", \"rb\") as infile:\n",
        "    PCA_test = pickle.load(infile) \n",
        "\n",
        "print(PCA_test.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4198, 8, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgVJE6tB_jgp",
        "outputId": "45bf70de-90f5-4ba8-beb1-99bd0270572b"
      },
      "source": [
        "PCA_test = PCA_test.reshape(4198, 8, 60, 1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(PCA_test, test_labels, verbose=2)\n",
        "y_pred = np.argmax(model.predict(PCA_test), axis=-1) #argmax returns the indice with the value that produces max from function -> eg. armax([0.9, 0.1]) returns 0\n",
        "print(str(y_pred[:100])+'\\n')\n",
        "print(test_labels[:100]) #TRY ARGMAX\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "132/132 - 0s - loss: 0.7624 - accuracy: 0.7323\n",
            "[1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1]\n",
            "\n",
            "[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYQ5YY5gw7eQ",
        "outputId": "14761aa0-e6b6-4e7d-d58d-a77d055846a0"
      },
      "source": [
        "#                         1    2    3    4    5    6\n",
        "char_matrix = np.array([['A', 'B', 'C', 'D', 'E', 'F'], # 7\n",
        "                        ['G', 'H', 'I', 'J', 'K', 'L'], # 8\n",
        "                        ['M', 'N', 'O', 'P', 'Q', 'R'], # 9\n",
        "                        ['S', 'T', 'U', 'V', 'W', 'X'], # 10\n",
        "                        ['Y', 'Z', '1', '2', '3', '4'], # 11\n",
        "                        ['5', '6', '7', '8', '9', '0']])# 12\n",
        "\n",
        "print(char_matrix.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHGjBE4UK8r-"
      },
      "source": [
        "#decoder to-do\n",
        "#for every 120 indices in decode array calculate the x, y coordinates with the highest activations\n",
        "#try using confidences as a metric to improve accuracy \n",
        "import collections\n",
        "\n",
        "def decode(y_pred, stim):\n",
        "  words = []\n",
        "  decode_array = np.array([y_pred, stim]).T\n",
        "  new_decode = np.array([decode_array[i:i+120] for i in range(0, len(decode_array), 120)], dtype=object)\n",
        "\n",
        "  for letter in new_decode:\n",
        "    col_count = []\n",
        "    row_count = []\n",
        "    for flash in letter:\n",
        "      if flash[0] == 1:\n",
        "        if flash[1] > 6 and flash[1] <= 12:\n",
        "          col_count.append(flash[1])\n",
        "        if flash[1] <= 6:\n",
        "          row_count.append(flash[1])\n",
        "          \n",
        "    # print(collections.Counter(col_count))\n",
        "\n",
        "    y = max(collections.Counter(col_count), key=collections.Counter(col_count).get)\n",
        "    x = max(collections.Counter(row_count), key=collections.Counter(row_count).get)\n",
        "    words.append(char_matrix[x-1, y-7])\n",
        "\n",
        "  return words\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvhkCxf2hRB",
        "outputId": "6d4891bf-a536-4f68-cd0a-3ac62cdce2a9"
      },
      "source": [
        "predictions = decode(y_pred, test_stim)\n",
        "answers = decode(test_labels, test_stim)\n",
        "print(answers)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['T', 'O', 'K', 'E', 'N', 'M', 'I', 'R', 'A', 'R', 'J', 'U', 'J', 'U', 'Y', 'M', 'A', 'N', 'S', 'O', 'C', 'I', 'N', 'C', 'O', 'J', 'U', 'E', 'G', 'O', 'Q', 'U', 'E', 'S', 'O']\n",
            "['E', 'P', 'A', 'F', 'Q', 'O', 'I', 'Z', 'C', 'Q', 'V', 'K', 'G', '2', 'M', 'P', 'Y', 'N', 'Z', 'S', '0', 'Q', 'F', 'X', 'F', 'Q', 'Y', 'Z', '8', 'Z', 'G', '1', 'I', 'Z', 'U']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "P4oHlWMf8vD0",
        "outputId": "94fbc2bc-7e35-455b-b2e7-31461d120626"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred)\n",
        "print(cm)\n",
        "# or\n",
        "#cm = np.array([[1401,    0],[1112, 0]])\n",
        "\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.title('Confusion matrix ')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2920  578]\n",
            " [ 546  154]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEFCAYAAACLjtDTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXvElEQVR4nO3debBcZZ3G8e9zE0CWsAZigCBRg1RAQYYCxC2KIqBW0FFUKGQYFBcQHbVGREswDFOM44oiGiAjiIJQoESMhBilkBmRBIyBBJWMgEkIhLBvIsHf/HHeHg6Xe7tP33T3vW+f52Oduue8Z3tb4fF937MpIjAzy9XAaFfAzGxDOMTMLGsOMTPLmkPMzLLmEDOzrDnEzCxrDrExRtKmkn4q6WFJl23AcY6SdE0n6zZaJL1W0h9Hux42Nsn3iY2MpCOBTwK7A48CS4AzIuL6DTzu0cDHgAMjYv0GV3SMkxTAtIhYMdp1sTy5JTYCkj4JfB34d2ASsAvwbWBmBw7/IuBPdQiwKiSNH+062BgXEZ7amICtgMeAdzfZZhOKkLs7TV8HNknrZgCrgE8Ba4E1wLFp3ReBvwFPp3McB5wGXFQ69q5AAOPT8j8Bf6ZoDd4BHFUqv76034HAIuDh9PfA0rprgdOB/07HuQaYOMxva9T/X0v1Pxw4DPgT8ABwSmn7/YDfAA+lbb8FbJzWXZd+y+Pp976ndPzPAPcA32+UpX1eks6xT1reEbgPmDHa/2x4Gp1p1CuQ2wQcAqxvhMgw28wCbgB2ALYH/gc4Pa2bkfafBWyU/uV/AtgmrR8cWsOGGLA58AjwsrRuMrBHmv//EAO2BR4Ejk77vS8tb5fWXwv8L7AbsGlaPnOY39ao/xdS/T+YQuSHwARgD+BJYGra/h+AA9J5dwVuAz5ROl4ALx3i+P9B8X8Gm5ZDLG3zQWA5sBkwH/jyaP9z4Wn0Jncn27cdsC6ad/eOAmZFxNqIuI+ihXV0af3Taf3TETGPohXyshHW5+/AnpI2jYg1EbFsiG3eCtweEd+PiPURcTHwB+DtpW3+KyL+FBFPApcCezc559MU439PA5cAE4FvRMSj6fzLgb0AIuKmiLghnfdO4LvA6yv8plMj4qlUn+eIiHOBFcBvKYL7cy2OZ33MIda++4GJLcZqdgTuKi3flcr+/xiDQvAJYIt2KxIRj1N0wT4MrJH0M0m7V6hPo047lZbvaaM+90fEM2m+ETL3ltY/2dhf0m6SrpJ0j6RHKMYRJzY5NsB9EfHXFtucC+wJfDMinmqxrfUxh1j7fgM8RTEONJy7KQboG3ZJZSPxOEW3qeGF5ZURMT8i3kzRIvkDxb/crerTqNPqEdapHedQ1GtaRGwJnAKoxT5NL5lL2oJinPF84DRJ23aiopYnh1ibIuJhivGgsyUdLmkzSRtJOlTSl9JmFwOfl7S9pIlp+4tGeMolwOsk7SJpK+CzjRWSJkmaKWlzimB9jKIrNtg8YDdJR0oaL+k9wHTgqhHWqR0TKMbtHkutxI8MWn8v8OI2j/kNYHFEfAD4GfCdDa6lZcshNgIR8RWKe8Q+TzGovRI4EfhJ2uTfgMXAUuAW4OZUNpJzLQB+lI51E88NnoFUj7sprti9nueHBBFxP/A2iiui91NcWXxbRKwbSZ3a9GngSIqrnudS/Jay04ALJD0k6YhWB5M0k+LiSuN3fhLYR9JRHauxZcU3u5pZ1twSM7OsOcTMLGsOMTPLmkPMzLLWlYdrNX7T0MYTunFo65Lp03Ye7SpYm5Yt/d26iNh+pPuP2/JFEeuf90DEkOLJ++ZHxCEjPVc3dSfENp7AJi9rebXcxpDLf/6l1hvZmLL75M0HP4XRllj/ZOV/T/+65OxWT1mMGr/mxKy2BMp/RMkhZlZXAgbGjXYtNphDzKzO1Oox1rHPIWZWW+5Omlnu3BIzs2wJt8TMLGdyS8zMMuerk2aWLw/sm1nOhLuTZpY5t8TMLF/uTppZzgSM88C+meXMY2Jmli93J80sd26JmVnW3BIzs2zJjx2ZWe782JGZ5csD+2aWO3cnzSxbfp+YmeXN3Ukzy50H9s0sax4TM7Nsyd1JM8udW2JmljP1QYjl35Y0sxEp3k6tSlPLY0lTJP1K0nJJyyR9PJWfJmm1pCVpOqy0z2clrZD0R0lvKZUfkspWSDq51bndEjOrKwkNdKwlth74VETcLGkCcJOkBWnd1yLiy889taYD7wX2AHYEfiFpt7T6bODNwCpgkaS5EbF8uBM7xMxqrFPdyYhYA6xJ849Kug3YqckuM4FLIuIp4A5JK4D90roVEfHnVL9L0rbDhpi7k2Y11kZ3cqKkxaXp+CbH3BV4JfDbVHSipKWS5kjaJpXtBKws7bYqlQ1XPiyHmFmNtRFi6yJi39I0e5jjbQFcDnwiIh4BzgFeAuxN0VL7Sqd/g7uTZnWlNHXqcNJGFAH2g4i4AiAi7i2tPxe4Ki2uBqaUdt85ldGkfEhuiZnVlKjWCqt4dVLA+cBtEfHVUvnk0mbvAG5N83OB90raRNJUYBpwI7AImCZpqqSNKQb/5zY7t1tiZjU2MNCxdsyrgaOBWyQtSWWnAO+TtDcQwJ3AhwAiYpmkSykG7NcDJ0TEMwCSTgTmA+OAORGxrNmJHWJmNdbBq5PXM3TndF6Tfc4AzhiifF6z/QZziJnVVYfHxEaLQ8ysxvrhsSOHmFlNNQb2c+cQM6uxDj52NGocYmZ1JXcnzSxzDjEzy5pDzMyy5YF9M8tf/hnmEDOrLXX0saNR4xAzqzF3J80sb/lnmEPMrM7cEjOzbFV9V9hY5xAzqzGHmJllzc9OmlnW3BIzs3z5AXAzy5mAPsgwh5hZffnqpJllbsAD+2aWLbk7aWYZE26JmVnm3BIzs6x5YN/M8uUxMTPLmZBfimhmeXNLzMyy5jExM8uXx8TMLGfFs5P5p1j+o3pmNmJStan1cTRF0q8kLZe0TNLHU/m2khZIuj393SaVS9JZklZIWippn9Kxjknb3y7pmFbndoiZ1djAgCpNFawHPhUR04EDgBMkTQdOBhZGxDRgYVoGOBSYlqbjgXOgCD3gVGB/YD/g1EbwDfsb2v3RZtYn9Ox79ltNrUTEmoi4Oc0/CtwG7ATMBC5Im10AHJ7mZwIXRuEGYGtJk4G3AAsi4oGIeBBYABzS7NweEzOrqTbfJzZR0uLS8uyImD3kcaVdgVcCvwUmRcSatOoeYFKa3wlYWdptVSobrnxYDjGz2mrrfWLrImLflkeUtgAuBz4REY+Ujx8RISlGVNUm3J00q7FODewXx9JGFAH2g4i4IhXfm7qJpL9rU/lqYEpp951T2XDlw3KImdWVOjewr6LJdT5wW0R8tbRqLtC4wngMcGWp/P3pKuUBwMOp2zkfOFjSNmlA/+BUNix3J81qqsP3ib0aOBq4RdKSVHYKcCZwqaTjgLuAI9K6ecBhwArgCeBYgIh4QNLpwKK03ayIeKDZiR1iZjXWqRCLiOspcnEoBw2xfQAnDHOsOcCcqud2iJnVWB/csO8QM6uzfnjsyCFmVld+ANzMcla8FDH/FHOImdXYQB80xdq6Tyzdu/GKblXGzHqrkze7jpaWISbpWklbpqfLbwbOlfTVVvuZ2dimDj4APpqqtMS2iohHgHdSPHW+P/Cm7lbLzHphQNWmsaxKiI1PzzwdAVzV5fqYWQ918H1io6ZKiM2ieHZpRUQskvRi4PbuVsvMuk0UVyir/Gcsa3l1MiIuAy4rLf8Z+MduVsrMemOMN7IqGTbEJH0TGPbdPxFxUldqZGa9kcGgfRXNWmKLm6wzsz7QBxk2fIhFxAXlZUmbRcQT3a+SmfWCqMnNrpJeJWk58Ie0vJekb3e9ZmbWdXW5Ovl1ii+Q3A8QEb8HXtfNSplZ91W9W3+sN9YqPTsZESsHDQA+053qmFkv9UN3skqIrZR0IBDpQwAfp/imnJllLv8Iq9ad/DDFa2R3Au4G9maY18qaWV764dnJKje7rgOO6kFdzKyHiquTo12LDVfl6uSLJf1U0n2S1kq6Mj16ZGY5U7Urk/1wdfKHwKXAZGBHikeQLu5mpcysN/qhO1klxDaLiO9HxPo0XQS8oNsVM7PuanQnc38VT7NnJ7dNsz+XdDJwCcWzlO+h+PClmWVurLeyqmg2sH8TRWg1fuWHSusC+Gy3KmVmvZF/hDV/dnJqLytiZr0lwbix3lesoNId+5L2BKZTGguLiAu7VSkz641+704CIOlUYAZFiM0DDgWuBxxiZpnrgwyrdHXyXcBBwD0RcSywF7BVV2tlZl0nxICqTWNZle7kkxHxd0nrJW0JrAWmdLleZtZtGbyhoooqIbZY0tbAuRRXLB8DftNshz2m7cwVV3+pA9WzXpmy3WajXQUbBZ0aE5M0B3gbsDYi9kxlpwEfBO5Lm50SEfPSus8Cx1G8EeekiJifyg8BvgGMA86LiDNbnbvKs5MfTbPfkXQ1sGVELK3+88xsLBIwrnNNse8B3+L5Y+Vfi4gvP+e80nTgvcAeFE8B/ULSbmn12cCbgVXAIklzI2J5sxM3u9l1n2brIuLmZgc2s7GvU3dYRMR1knatuPlM4JKIeAq4Q9IKYL+0bkX6ohqSLknbjizEgK80qzPwxooVNrMxqo0Qmyip/PGg2RExu8J+J0p6P8WHhz4VEQ9SvNbrhtI2q1IZwMpB5fu3OkGzm13fUKGCZpap4tXTlVNsXUTs2+YpzgFOp2j0nE7RMPrnNo/RUqWbXc2sP3Xzhv2IuLcxL+lc4Kq0uJrn3uGwcyqjSfmwqtwnZmZ9qpsfCpE0ubT4DuDWND8XeK+kTSRNBaYBNwKLgGmSpkramGLwf26r87glZlZTAsZ37haLiyme7JkoaRVwKjBD0t4U3ck7SS+RiIhlki6lGLBfD5wQEc+k45wIzKe4xWJORCxrde4qjx2J4vXUL46IWZJ2AV4YETe2+0PNbGzp1B0WEfG+IYrPb7L9GcAZQ5TPo81XfVXpTn4beBXQqOSjFPdymFnGVPGRo3547Gj/iNhH0u8AIuLB1F81s8yN8XyqpEqIPS1pHEW/FknbA3/vaq3MrCf64HVilULsLODHwA6SzqB4q8Xnu1orM+s6UZOXIkbEDyTdRPE6HgGHR4S/AG6Wuww+AlJFlauTuwBPAD8tl0XEX7pZMTPrPvXBW/ardCd/xrMfDHkBMBX4I8UT6GaWqX75AniV7uTLy8vp7RYfHWZzM8tILUJssIi4WVLLJ8vNbOyry4dCPllaHAD2Ae7uWo3MrCeKT7aNdi02XJWW2ITS/HqKMbLLu1MdM+ulsX43fhVNQyzd5DohIj7do/qYWY/0/cC+pPERsV7Sq3tZITPrnT5oiDVtid1IMf61RNJc4DLg8cbKiLiiy3Uzs64SAzW5T+wFwP0U79Rv3C8WgEPMLGOi/1tiO6Qrk7fybHg1RFdrZWbdJxjfB4NizUJsHLAFDNnedIiZZa4OLbE1ETGrZzUxs57r91ss8v91ZtZUH2RY0xA7qGe1MLOeE/3xubNmH899oJcVMbMeU/93J82sjxV37DvEzCxj+UeYQ8ys1vqgIeYQM6sv1eN9YmbWn/r+6qSZ9T8P7JtZvlST11ObWX9yd9LMstcPLbF+CGIzGyFVnFoeR5ojaa2kW0tl20paIOn29HebVC5JZ0laIWlp+gxkY59j0va3Szqmym9wiJnVlIBxUqWpgu8BhwwqOxlYGBHTgIVpGeBQYFqajgfOgSL0gFOB/YH9gFMbwdeMQ8ysxqRqUysRcR0w+HnrmcAFaf4C4PBS+YVRuAHYWtJk4C3Agoh4ICIeBBbw/GB8Ho+JmdWWUPUHjyZKWlxanh0Rs1vsMyki1qT5e4BJaX4nYGVpu1WpbLjyphxiZjXWxrj+uojYd6TniYiQ1JU3Qrs7aVZTxS0WqjSN0L2pm0j6uzaVrwamlLbbOZUNV96UQ8ysriqOh23AXRhzgcYVxmOAK0vl709XKQ8AHk7dzvnAwZK2SQP6B6eyptydNKuxTj12JOliYAbF2NkqiquMZwKXSjoOuAs4Im0+DzgMWAE8ARwLxYtYJZ0OLErbzaryclaHmFlNFS9F7MyxIuJ9w6x63mvuIyKAE4Y5zhxgTjvndoiZ1VgbVyfHLIeYWY31wVNHDjGzOnNLzMyy1ckxsdHkEDOrK8kvRTSzvOUfYQ4xs9rydyfNLHv5R5hDzKze+iDFHGJmNebupJllLf8Ic4iZ1VsfpJhDzKymio+A5J9iDjGzutqwd4WNGQ4xsxrrgwxziJnVl/ri47kOMbMa64MMc4iZ1VXVr3uPdQ4xszrrgxRziJnVmG+xMLOseUzMzPLl+8TMLHfuTppZtoRbYmaWuT7IMIeYWa31QYo5xMxqzC9FNLOs5R9hDjGzeuuDFHOImdVUv7wUcWC0K2BmoyTd7FplqnQ46U5Jt0haImlxKttW0gJJt6e/26RySTpL0gpJSyXtM9Kf4RAzqzFVnNrwhojYOyL2TcsnAwsjYhqwMC0DHApMS9PxwDkj/Q0OMbPaKl6KWGXaADOBC9L8BcDhpfILo3ADsLWkySM5gUPMrMY62Z0EArhG0k2Sjk9lkyJiTZq/B5iU5ncCVpb2XZXK2uaBfbOaarOrOLExzpXMjojZg7Z5TUSslrQDsEDSH8orIyIkxUjrOxyHmFmdVU+xdaVxriFFxOr0d62kHwP7AfdKmhwRa1J3cW3afDUwpbT7zqmsbe5OmtWYKv6n5XGkzSVNaMwDBwO3AnOBY9JmxwBXpvm5wPvTVcoDgIdL3c62uCVmVmMdfOpoEvDjdBFgPPDDiLha0iLgUknHAXcBR6Tt5wGHASuAJ4BjR3pih5hZXQkGOhRiEfFnYK8hyu8HDhqiPIATOnFuh5hZreV/x75DzKym/FJEM8teH2SYQ8ysztwSM7OsbeAjRWOCQ8ysxvKPMIeYWW21+VzkmOUQM6uxfngpokPMrM7yzzCHmFmd9UGGOcTM6kv+ZJuZ5atf7tj3q3jMLGtuiZnVWD+0xBxiZjXmWyzMLF++2dXMctYvA/sOMbMac3fSzLLmlpiZZa0PMswhZlZrfZBiDjGzmhL0xWNHKr6c1OGDSvdRfGPOzLrnRRGx/Uh3lnQ1MLHi5usi4pCRnqubuhJiZma94mcnzSxrDjEzy5pDzMyy5hDrIUnPSFoi6VZJl0nabAOO9T1J70rz50ma3mTbGZIOHME57pT0vIHf4coHbfNYm+c6TdKn262jmUOst56MiL0jYk/gb8CHyysljeiWl4j4QEQsb7LJDKDtEDPLgUNs9PwaeGlqJf1a0lxguaRxkv5T0iJJSyV9CECFb0n6o6RfADs0DiTpWkn7pvlDJN0s6feSFkralSIs/yW1Al8raXtJl6dzLJL06rTvdpKukbRM0nlUuBVS0k8k3ZT2OX7Quq+l8oWStk9lL5F0ddrn15J2H+KYJ0lann7/JSP7r9dqIyI89WgCHkt/xwNXAh+haCU9DkxN644HPp/mNwEWA1OBdwILgHHAjsBDwLvSdtcC+wLbAytLx9o2/T0N+HSpHj8EXpPmdwFuS/NnAV9I828FApg4xO+4s1FeOsemwK3Admk5gKPS/BeAb6X5hcC0NL8/8MvBdQTuBjZJ81uP9v9unsb25Dv2e2tTSUvS/K+B8ym6eTdGxB2p/GDgFY3xLmArYBrwOuDiiHgGuFvSL4c4/gHAdY1jRcQDw9TjTcD00ifst5S0RTrHO9O+P5P0YIXfdJKkd6T5Kamu9wN/B36Uyi8CrkjnOBC4rHTuTYY45lLgB5J+AvykQh2sxhxivfVkROxdLkj/Mj9eLgI+FhHzB213WAfrMQAcEBF/HaIulUmaQRGIr4qIJyRdC7xgmM0jnfehwf8dDOGtFIH6duBzkl4eEevbqpzVhsfExp75wEckbQQgaTdJmwPXAe9JY2aTgTcMse8NwOskTU37bpvKHwUmlLa7BvhYY0FSI1SuA45MZYcC27So61bAgynAdqdoCTYMAI3W5JHA9RHxCHCHpHenc0jSXuUDShoApkTEr4DPpHNs0aIeVmMOsbHnPGA5cLOkW4HvUrSYfwzcntZdCPxm8I4RcR/FmNoVkn7Ps925nwLvaAzsAycB+6aB8+U8e5X0ixQhuIyiW/mXFnW9Ghgv6TbgTIoQbXgc2C/9hjcCs1L5UcBxqX7LgJmDjjkOuEjSLcDvgLMi4qEW9bAa87OTZpY1t8TMLGsOMTPLmkPMzLLmEDOzrDnEzCxrDjEzy5pDzMyy9n9peRVuiQyY1gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AowdkQ5POzE7"
      },
      "source": [
        "Without Padding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5YXd0gzUwRE",
        "outputId": "abead9a0-4d76-4eb6-ba19-e51ca39e48da"
      },
      "source": [
        "ink = (5000, 8, 120, 1)\n",
        "ink = tf.random.normal(ink)\n",
        "print(ink.shape)\n",
        "PCA_train = PCA_train.reshape(504, 8, 120, 1)\n",
        "#l2\n",
        "L2 = Conv2D(20, (8, 1), activation=\"relu\", input_shape=(8, 120, 1))(PCA_train)\n",
        "print(L2.shape) #0th index: # of batches, 1st index: height of output, 2nd index: width of output, 3rd index: depth -> # of filters\n",
        "#l3\n",
        "L3_1 = Conv2D(filters=16, kernel_size=(1, 5), strides=5, activation=\"relu\", input_shape=(1, 120, 20))(L2)\n",
        "print(L3_1.shape)\n",
        "\n",
        "L3_2 = Conv2D(filters=16, kernel_size=(1, 10), strides=10, activation=\"relu\", input_shape=(1, 120, 20))(L2)\n",
        "print(L3_2.shape)\n",
        "\n",
        "L3_3 = Conv2D(filters=16, kernel_size=(1, 15), strides=15, activation=\"relu\", input_shape=(1, 120, 20))(L2)\n",
        "print(L3_3.shape)\n",
        "\n",
        "#L4\n",
        "concatted = concatenate([L3_1, L3_2, L3_3], axis=2) # merge the outputs of the two models\n",
        "print(concatted.shape)\n",
        "dp = tf.keras.layers.Dropout(.5)(concatted)\n",
        "print(dp.shape)\n",
        "\n",
        "#L5\n",
        "L5_1 = Conv2D(filters=16, kernel_size=(1, 2), strides=2, activation=\"relu\", input_shape=(1, 44, 16))(dp)\n",
        "print(L5_1.shape)\n",
        "\n",
        "L5_2 = Conv2D(filters=16, kernel_size=(1, 4), strides=4, activation=\"relu\", input_shape=(1, 44, 16))(dp)\n",
        "print(L5_2.shape)\n",
        "\n",
        "L5_3 = Conv2D(filters=16, kernel_size=(1, 11), strides=11, activation=\"relu\", input_shape=(1, 44, 16))(dp)\n",
        "print(L5_3.shape)\n",
        "\n",
        "#L6\n",
        "concatted2 = concatenate([L5_1, L5_2, L5_3], axis=2) # merge the outputs of the two models\n",
        "print(concatted2.shape)\n",
        "dp2 = tf.keras.layers.Dropout(.5)(concatted2)\n",
        "print(dp2.shape)\n",
        "\n",
        "#L7\n",
        "mxpool = layers.MaxPooling2D((2, 2), strides=2)(dp2)\n",
        "print(mxpool.shape)\n",
        "\n",
        "#L8 \n",
        "flat = layers.Flatten()(mxpool)\n",
        "dense = layers.Dense(100, activation='relu')(flat)\n",
        "dense2 = layers.Dense(2, activation='relu')(flat)\n",
        "print(dense.shape)\n",
        "print(dense2.shape)\n",
        "\n",
        "#L9\n",
        "sftymax = layers.Softmax(axis=1)(dense2)\n",
        "print(sftymax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 8, 120, 1)\n",
            "(504, 1, 120, 20)\n",
            "(504, 1, 24, 16)\n",
            "(504, 1, 12, 16)\n",
            "(504, 1, 8, 16)\n",
            "(504, 1, 44, 16)\n",
            "(504, 1, 44, 16)\n",
            "(504, 1, 22, 16)\n",
            "(504, 1, 11, 16)\n",
            "(504, 1, 4, 16)\n",
            "(504, 1, 37, 16)\n",
            "(504, 1, 37, 16)\n",
            "(504, 0, 18, 16)\n",
            "(504, 100)\n",
            "(504, 2)\n",
            "tf.Tensor(\n",
            "[[0.5 0.5]\n",
            " [0.5 0.5]\n",
            " [0.5 0.5]\n",
            " ...\n",
            " [0.5 0.5]\n",
            " [0.5 0.5]\n",
            " [0.5 0.5]], shape=(504, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFoUruewOvEr"
      },
      "source": [
        "With Padding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTJdMWLYLiiU",
        "outputId": "a92eea65-ffe0-4ff7-d323-05996f260ffd"
      },
      "source": [
        "ink = (5000, 8, 60, 1)\n",
        "ink = tf.random.normal(ink)\n",
        "print(ink.shape)\n",
        "\n",
        "#l2\n",
        "L2 = Conv2D(20, (8, 1), activation=\"relu\", strides=(8, 1), padding=\"same\", input_shape=(8, 60, 1))(ink)\n",
        "print(L2.shape) #0th index: # of batches, 1st index: height of output, 2nd index: width of output, 3rd index: depth -> # of filters\n",
        "#L3\n",
        "L3_1 = Conv2D(filters=16, kernel_size=(1, 5), strides=(1, 5), padding=\"same\", activation=\"relu\")(L2)\n",
        "print(L3_1.shape)\n",
        "\n",
        "L3_2 = Conv2D(filters=16, kernel_size=(1, 10), strides=(1, 10), padding=\"same\", activation=\"relu\")(L2)\n",
        "print(L3_2.shape)\n",
        "\n",
        "L3_3 = Conv2D(filters=16, kernel_size=(1, 15), strides=(1, 15), padding=\"same\", activation=\"relu\")(L2)\n",
        "print(L3_3.shape)\n",
        "\n",
        "#L4\n",
        "concatted = concatenate([L3_1, L3_2, L3_3], axis=2) # merge the outputs of the two models\n",
        "print(concatted.shape)\n",
        "dp = tf.keras.layers.Dropout(.5)(concatted)\n",
        "print(dp.shape)\n",
        "\n",
        "# #L5\n",
        "# L5_1 = Conv2D(filters=16, kernel_size=(1, 2), strides=(1, 2), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(dp)\n",
        "# print(L5_1.shape)\n",
        "\n",
        "# L5_2 = Conv2D(filters=16, kernel_size=(1, 4), strides=(1, 4), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(dp)\n",
        "# print(L5_2.shape)\n",
        "\n",
        "# L5_3 = Conv2D(filters=16, kernel_size=(1, 11), strides=(1, 11), padding=\"same\", activation=\"relu\", input_shape=(1, 44, 16))(dp)\n",
        "# print(L5_3.shape)\n",
        "\n",
        "# #L6\n",
        "# concatted2 = concatenate([L5_1, L5_2, L5_3], axis=2) # merge the outputs of the two models\n",
        "# print(concatted2.shape)\n",
        "# dp2 = tf.keras.layers.Dropout(.5)(concatted2)\n",
        "# print(dp2.shape)\n",
        "\n",
        "# #L7\n",
        "# mxpool = layers.MaxPooling2D((2, 2), strides=2)(dp2)\n",
        "# print(mxpool.shape)\n",
        "\n",
        "# #L8 \n",
        "# flat = layers.Flatten()(mxpool)\n",
        "# dense = layers.Dense(100, activation='relu')(flat)\n",
        "# dense2 = layers.Dense(2, activation='relu')(flat)\n",
        "# print(dense.shape)\n",
        "# print(dense2.shape)\n",
        "\n",
        "# #L9\n",
        "# sftymax = layers.Softmax(axis=1)(dense2)\n",
        "# print(sftymax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 8, 60, 1)\n",
            "(5000, 1, 60, 20)\n",
            "(5000, 1, 12, 16)\n",
            "(5000, 1, 6, 16)\n",
            "(5000, 1, 4, 16)\n",
            "(5000, 1, 22, 16)\n",
            "(5000, 1, 22, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}